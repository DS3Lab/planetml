#!/bin/bash
#BSUB -n 1                      # 1 cores
#BSUB -W 3:59                   # 3 hours run-time
#BSUB -R "rusage[mem=8000]"     # 11 GB per core
#BSUB -R "rusage[ngpus_excl_p=1]"
#BSUB -R "select[gpu_mtotal0>=10000]"
#BSUB -o /nfs/iiscratch-zhang.inf.ethz.ch/export/zhang/export/fm/new/exec_log/gpt_j_6B_out.%J
#BSUB -e /nfs/iiscratch-zhang.inf.ethz.ch/export/zhang/export/fm/new/exec_log/gpt_j_6B_err.%J
. /cluster/apps/local/env2lmod.sh
module load gcc/8.2.0 python_gpu/3.9.9 cuda/11.0.3 eth_proxy zsh/5.8
source /nfs/iiscratch-zhang.inf.ethz.ch/export/zhang/export/fm/new/planetml_env/bin/activate
cd /nfs/iiscratch-zhang.inf.ethz.ch/export/zhang/export/fm/GPT-home-private      # Change directory

world_size=4
DIST_CONF="--pp-mode pipe_sync_sample_mask_token_pipe --pipeline-group-size $world_size --cuda-id 0"
MODEL_CONF="--model-type gptj --model-name /nfs/iiscratch-zhang.inf.ethz.ch/export/zhang/export/fm/pretrained_models/gpt-j-6B --num-iters 99999999999"
INFERENCE_CONF="--fp16 --budget 5000 --batch-size 1 --token-micro-batch-size 1 --input-seq-length 1024 --generate-seq-length 64 --top-p 1 --temperature 0 --num-layers 7"
COOR_CONF="--coordinator-server-ip 10.6.7.244 --working-directory /nfs/iiscratch-zhang.inf.ethz.ch/export/zhang/export/fm/new/working_dir --profiling no-profiling  --net-interface access"
#!/bin/bash

export NCCL_SOCKET_IFNAME=access
export GLOO_SOCKET_IFNAME=access
export NCCL_DEBUG=INFO
export NCCL_IB_DISABLE=1
export NCCL_P2P_DISABLE=1

python -u dist_batch_and_latency_inference_w_httpclient.py $DIST_CONF $MODEL_CONF $INFERENCE_CONF $COOR_CONF \
